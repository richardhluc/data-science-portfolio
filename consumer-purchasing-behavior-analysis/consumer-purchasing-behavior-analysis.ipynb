{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbc90589-af0e-4a8c-bef2-921b16db951a",
   "metadata": {},
   "source": [
    "# =================================================================\n",
    "# Consumer Purchasing Behavior Analysis\n",
    "# =================================================================\n",
    "# Goal: Segment customers into meaningful behavioral groups using PCA and K-Means\n",
    "# to support targeted marketing, promotions, and retention strategies.\n",
    "# Key Tasks:\n",
    "#   1. Load and clean the marketing campaign dataset.\n",
    "#   2. Engineer key features (age, tenure, total spending, campaign responses).\n",
    "#   3. Scale/encode features, reduce dimensionality with PCA.\n",
    "#   4. Use K-Means clustering with silhouette and elbow methods to choose k.\n",
    "#   5. Profile and interpret clusters (personas) for business insights.\n",
    "# Tools: Python, pandas, numpy, matplotlib, seaborn, scikit-learn, joblib\n",
    "# Dataset: Kaggle (Consumer Behavior dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b61e03f-ff7f-484c-8be6-faba8dd27065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- IMPORT LIBRARIES ----------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import math\n",
    "import os\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc60883-4f4e-44d5-a89c-9c02174784ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- PROJECT SETUP ----------\n",
    "project_dir = Path.cwd()\n",
    "\n",
    "fig_dir     = project_dir / \"figures\"\n",
    "models_dir  = project_dir / \"models\"\n",
    "outputs_dir = project_dir / \"outputs\"\n",
    "\n",
    "for d in [fig_dir, models_dir, outputs_dir]:\n",
    "    d.mkdir(exist_ok=True)\n",
    "\n",
    "def save_plot(filename, width=8, height=5, dpi=300):\n",
    "    \"\"\"\n",
    "    Save the current Matplotlib figure into the figures/ folder.\n",
    "    \"\"\"\n",
    "    plt.gcf().set_size_inches(width, height)\n",
    "    plt.savefig(fig_dir / filename, dpi=dpi, bbox_inches=\"tight\")\n",
    "\n",
    "def save_output(df, filename):\n",
    "    \"\"\"\n",
    "    Save a pandas DataFrame into the outputs/ directory as CSV.\n",
    "    \"\"\"\n",
    "    filepath = outputs_dir / filename\n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(f\"Saved output: {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "# -------------------- PLOT STYLE --------------------\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rc(\"font\", size=14)\n",
    "plt.rc(\"axes\", labelsize=14, titlesize=14)\n",
    "plt.rc(\"legend\", fontsize=12)\n",
    "plt.rc(\"xtick\", labelsize=10)\n",
    "plt.rc(\"ytick\", labelsize=10)\n",
    "\n",
    "# ---------- AXIS LABELS WITH UNITS ----------\n",
    "axis_labels = {\n",
    "    \"Age\": \"Age (years)\",\n",
    "    \"Income\": \"Annual Income (currency units)\",\n",
    "    \"Total_Spent\": \"Total Spending (currency units)\",\n",
    "    \"Customer_Tenure\": \"Customer Tenure (days since enrollment)\",\n",
    "    \"Recency\": \"Recency (days since last purchase)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971b4f62-0f08-4644-8d59-40d4d1faafae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- LOAD DATA --------------------\n",
    "data_path = project_dir / \"consumer_behavior_data.csv\"\n",
    "\n",
    "consumer_behavior_df = pd.read_csv(\n",
    "    data_path,\n",
    "    sep=\"\\t\"\n",
    ")\n",
    "\n",
    "print(\"Raw shape:\", consumer_behavior_df.shape)\n",
    "\n",
    "print(\"\\nHead (first 5 rows):\")\n",
    "print(consumer_behavior_df.head().to_string(index=False))\n",
    "\n",
    "print(\"\\nDtypes:\")\n",
    "print(consumer_behavior_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf40673-8b35-4419-a2a6-bac0064cc2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- DATA CLEANING & FEATURE ENGINEERING ----------\n",
    "# Parse dates\n",
    "consumer_behavior_df[\"Dt_Customer\"] = pd.to_datetime(\n",
    "    consumer_behavior_df[\"Dt_Customer\"],\n",
    "    dayfirst=True,          \n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Drop rows with invalid dates\n",
    "consumer_behavior_df = consumer_behavior_df.dropna(subset=[\"Dt_Customer\"])\n",
    "\n",
    "# Handle missing Income\n",
    "if consumer_behavior_df[\"Income\"].isna().sum() > 0:\n",
    "    consumer_behavior_df = consumer_behavior_df.dropna(subset=[\"Income\"])\n",
    "\n",
    "# Age\n",
    "consumer_behavior_df[\"Age\"] = 2025 - consumer_behavior_df[\"Year_Birth\"]\n",
    "\n",
    "# Remove unrealistic ages\n",
    "consumer_behavior_df = consumer_behavior_df[\n",
    "    (consumer_behavior_df[\"Age\"] >= 18) & (consumer_behavior_df[\"Age\"] <= 90)\n",
    "]\n",
    "\n",
    "# Children & Parent flag\n",
    "consumer_behavior_df[\"Children\"] = (\n",
    "    consumer_behavior_df[\"Kidhome\"] + consumer_behavior_df[\"Teenhome\"]\n",
    ")\n",
    "consumer_behavior_df[\"IsParent\"] = (consumer_behavior_df[\"Children\"] > 0).astype(int)\n",
    "\n",
    "# Customer tenure (days since enrollment)\n",
    "max_dt = consumer_behavior_df[\"Dt_Customer\"].max()\n",
    "consumer_behavior_df[\"Customer_Tenure\"] = (\n",
    "    max_dt - consumer_behavior_df[\"Dt_Customer\"]\n",
    ").dt.days\n",
    "\n",
    "# Total amount spent across product categories\n",
    "mnt_cols = [\n",
    "    \"MntWines\", \"MntFruits\", \"MntMeatProducts\",\n",
    "    \"MntFishProducts\", \"MntSweetProducts\", \"MntGoldProds\"\n",
    "]\n",
    "\n",
    "consumer_behavior_df[\"Total_Spent\"] = consumer_behavior_df[mnt_cols].sum(axis=1)\n",
    "\n",
    "# Total accepted campaigns\n",
    "campaign_cols = [\"AcceptedCmp1\", \"AcceptedCmp2\", \"AcceptedCmp3\",\n",
    "                 \"AcceptedCmp4\", \"AcceptedCmp5\"]\n",
    "existing_campaign_cols = [c for c in campaign_cols if c in consumer_behavior_df.columns]\n",
    "consumer_behavior_df[\"Total_Accepted_Campaigns\"] = consumer_behavior_df[existing_campaign_cols].sum(axis=1)\n",
    "\n",
    "print(\"\\nAfter cleaning & feature engineering (sample rows):\")\n",
    "cols_preview = [\n",
    "    \"ID\", \"Age\", \"Education\", \"Marital_Status\", \"Income\",\n",
    "    \"Children\", \"IsParent\", \"Customer_Tenure\", \"Total_Spent\",\n",
    "    \"Recency\", \"Total_Accepted_Campaigns\"\n",
    "]\n",
    "print(consumer_behavior_df[cols_preview].head().to_string(index=False))\n",
    "\n",
    "print(\"\\nMissing values by column:\")\n",
    "print(consumer_behavior_df.isnull().sum().to_string())\n",
    "\n",
    "# ---------- EXPLORATORY DATA ANALYSIS (EDA) ----------\n",
    "# Histograms of key continuous features\n",
    "eda_features = [\"Age\", \"Income\", \"Total_Spent\", \"Customer_Tenure\", \"Recency\"]\n",
    "n_cols = 3\n",
    "n_features = len(eda_features)\n",
    "n_rows = math.ceil(n_features / n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(eda_features):\n",
    "    axes[i].hist(consumer_behavior_df[col], bins=30, edgecolor=\"black\")\n",
    "    axes[i].set_title(f\"Distribution of {col}\")\n",
    "    axes[i].set_xlabel(axis_labels.get(col, col))\n",
    "    axes[i].set_ylabel(\"Frequency\")\n",
    "\n",
    "# Remove any empty subplot axes\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.suptitle(\"Key Continuous Feature Distributions\", y=1.02)\n",
    "plt.tight_layout()\n",
    "save_plot(\"eda_histograms_key_features.png\", width=15, height=4 * n_rows, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot of Total_Spent by Marital_Status\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=consumer_behavior_df, x=\"Marital_Status\", y=\"Total_Spent\")\n",
    "plt.title(\"Total Spending by Marital Status\")\n",
    "plt.xlabel(\"Marital Status\")\n",
    "plt.ylabel(axis_labels[\"Total_Spent\"])\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "save_plot(\"total_spent_by_marital_status.png\", width=8, height=6, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaf04b1-f9a4-41a6-859c-d0ef428c358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- FEATURE SELECTION FOR CLUSTERING ----------\n",
    "numeric_features = [\n",
    "    \"Age\",\n",
    "    \"Income\",\n",
    "    \"Children\",\n",
    "    \"Customer_Tenure\",\n",
    "    \"Recency\",\n",
    "    \"Total_Spent\",\n",
    "    \"NumDealsPurchases\",\n",
    "    \"NumWebPurchases\",\n",
    "    \"NumCatalogPurchases\",\n",
    "    \"NumStorePurchases\",\n",
    "    \"NumWebVisitsMonth\",\n",
    "    \"Complain\",\n",
    "    \"Total_Accepted_Campaigns\"\n",
    "] + mnt_cols\n",
    "\n",
    "categorical_features = [\"Education\", \"Marital_Status\"]\n",
    "\n",
    "consumer_behavior_df_model = consumer_behavior_df[\n",
    "    numeric_features + categorical_features\n",
    "].dropna()\n",
    "\n",
    "print(\"\\nModeling dataframe shape:\", consumer_behavior_df_model.shape)\n",
    "\n",
    "X = consumer_behavior_df_model.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c852f902-10a6-4c74-b649-cfedc45d7397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- PREPROCESSING PIPELINE ----------\n",
    "numeric_transformer = RobustScaler()\n",
    "categorical_transformer = OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ---------- PCA (DIMENSIONALITY REDUCTION) ----------\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "pca_full = PCA(random_state=RANDOM_STATE)\n",
    "X_pca_full = pca_full.fit_transform(X_preprocessed)\n",
    "\n",
    "explained_variance_ratio = pca_full.explained_variance_ratio_\n",
    "cumulative_explained = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(\n",
    "    range(1, len(cumulative_explained) + 1),\n",
    "    cumulative_explained,\n",
    "    marker=\"o\"\n",
    ")\n",
    "plt.title(\"PCA – Cumulative Explained Variance\")\n",
    "plt.xlabel(\"Number of Principal Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance Ratio\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "save_plot(\"pca_cumulative_explained_variance.png\", width=8, height=5, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Save explained-variance table\n",
    "pca_variance_df = pd.DataFrame({\n",
    "    \"component\": np.arange(1, len(explained_variance_ratio) + 1),\n",
    "    \"explained_variance_ratio\": explained_variance_ratio,\n",
    "    \"cumulative_explained_variance\": cumulative_explained\n",
    "})\n",
    "save_output(pca_variance_df, \"pca_explained_variance.csv\")\n",
    "\n",
    "# Choose a fixed number of components\n",
    "N_COMPONENTS = 8\n",
    "pca = PCA(n_components=N_COMPONENTS, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16efe98-df8d-4687-b092-22b735019d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- K-MEANS MODEL SELECTION (SILHOUETTE & ELBOW) ----------\n",
    "k_values = range(2, 9)\n",
    "sil_scores = []\n",
    "inertias = []\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans_k = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=10)\n",
    "\n",
    "    # Build a small pipeline for each k\n",
    "    pipe_k = Pipeline([\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"pca\", PCA(n_components=N_COMPONENTS, random_state=RANDOM_STATE)),\n",
    "        (\"cluster\", kmeans_k)\n",
    "    ])\n",
    "\n",
    "    X_pre_k = pipe_k[\"preprocess\"].fit_transform(X)\n",
    "    X_pca_k = pipe_k[\"pca\"].fit_transform(X_pre_k)\n",
    "    labels_k = pipe_k[\"cluster\"].fit_predict(X_pca_k)\n",
    "\n",
    "    sil = silhouette_score(X_pca_k, labels_k)\n",
    "    sil_scores.append(sil)\n",
    "    inertias.append(pipe_k[\"cluster\"].inertia_)\n",
    "\n",
    "# Silhouette plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(x=list(k_values), y=sil_scores, marker=\"o\")\n",
    "plt.title(\"Silhouette Score vs Number of Clusters (k)\")\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "save_plot(\"silhouette_score_vs_k.png\", width=8, height=5, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Elbow plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(x=list(k_values), y=inertias, marker=\"o\")\n",
    "plt.title(\"Elbow Method – Inertia vs Number of Clusters (k)\")\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Inertia (Within-Cluster SSE)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "save_plot(\"elbow_method_inertia_vs_k.png\", width=8, height=5, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Save k-selection metrics\n",
    "k_selection_df = pd.DataFrame({\n",
    "    \"k\": list(k_values),\n",
    "    \"silhouette_score\": sil_scores,\n",
    "    \"inertia\": inertias\n",
    "})\n",
    "save_output(k_selection_df, \"k_selection_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e1438c-db9a-4f0a-b125-8141933ebb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- FIT FINAL K-MEANS MODEL ----------\n",
    "# Choose final k based on silhouette & elbow\n",
    "BEST_K = 4\n",
    "\n",
    "final_kmeans = KMeans(n_clusters=BEST_K, random_state=RANDOM_STATE, n_init=10)\n",
    "\n",
    "clustering_pipeline = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"pca\", pca),\n",
    "    (\"cluster\", final_kmeans)\n",
    "])\n",
    "\n",
    "clustering_pipeline.fit(X)\n",
    "\n",
    "# Transform data for visualization & store cluster labels\n",
    "X_pca_final = clustering_pipeline[\"pca\"].transform(\n",
    "    clustering_pipeline[\"preprocess\"].transform(X)\n",
    ")\n",
    "cluster_labels = clustering_pipeline[\"cluster\"].labels_\n",
    "\n",
    "consumer_behavior_df_model[\"cluster\"] = cluster_labels\n",
    "\n",
    "# ---------- CLUSTER PROFILING ----------\n",
    "cluster_profile = (\n",
    "    consumer_behavior_df_model\n",
    "    .groupby(\"cluster\")[numeric_features + [\"Total_Spent\"]]\n",
    "    .mean()\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "print(\"\\nCluster Profile (mean values):\")\n",
    "print(cluster_profile.to_string())\n",
    "\n",
    "# Save cluster profile\n",
    "cluster_profile_out = cluster_profile.reset_index()\n",
    "save_output(cluster_profile_out, \"cluster_profile.csv\")\n",
    "\n",
    "# Cluster sizes\n",
    "cluster_counts = consumer_behavior_df_model[\"cluster\"].value_counts().sort_index()\n",
    "print(\"\\nCluster sizes (number of customers per cluster):\")\n",
    "print(cluster_counts)\n",
    "\n",
    "cluster_counts_df = cluster_counts.reset_index()\n",
    "cluster_counts_df.columns = [\"cluster\", \"count\"]\n",
    "save_output(cluster_counts_df, \"cluster_sizes.csv\")\n",
    "\n",
    "# Education distribution by cluster\n",
    "print(\"\\nEducation distribution by cluster (proportion):\")\n",
    "edu_dist = (\n",
    "    consumer_behavior_df_model.groupby(\"cluster\")[\"Education\"]\n",
    "    .value_counts(normalize=True)\n",
    "    .rename(\"proportion\")\n",
    ")\n",
    "print(edu_dist.to_string())\n",
    "\n",
    "edu_dist_df = edu_dist.reset_index()\n",
    "save_output(edu_dist_df, \"education_distribution_by_cluster.csv\")\n",
    "\n",
    "# Marital status distribution by cluster\n",
    "print(\"\\nMarital status distribution by cluster (proportion):\")\n",
    "marital_dist = (\n",
    "    consumer_behavior_df_model.groupby(\"cluster\")[\"Marital_Status\"]\n",
    "    .value_counts(normalize=True)\n",
    "    .rename(\"proportion\")\n",
    ")\n",
    "print(marital_dist.to_string())\n",
    "\n",
    "marital_dist_df = marital_dist.reset_index()\n",
    "save_output(marital_dist_df, \"marital_status_distribution_by_cluster.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91f0132-57e5-4182-91fb-2079322d3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- PCA 2D SCATTERPLOT ----------\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(\n",
    "    X_pca_final[:, 0],\n",
    "    X_pca_final[:, 1],\n",
    "    c=cluster_labels,\n",
    "    cmap=\"viridis\",\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title(\"Customer Segments (PCA 2D Projection)\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "save_plot(\"pca_clusters_scatter.png\", width=8, height=6, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f99c74-d6c7-430c-a346-a84441d838a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SAVE MODEL ---\n",
    "model_path = models_dir / \"customer_personality_clustering_pipeline.pkl\"\n",
    "joblib.dump(clustering_pipeline, model_path)\n",
    "print(f\"\\nSaved clustering pipeline to: {model_path}\")\n",
    "\n",
    "# -------------------- PIPELINE COMPLETE --------------------\n",
    "print(\"\\nPipeline complete:\")\n",
    "print(\"- Project setup (figures/, outputs/, models/ directories)\")\n",
    "print(\"- Data loading & validation (shape, head preview, dtypes)\")\n",
    "print(\"- Data cleaning & feature engineering (age, tenure, spending, campaigns)\")\n",
    "print(\"- Missing-value handling and sanity checks\")\n",
    "print(\"- Exploratory data analysis (feature distributions, spending by marital status)\")\n",
    "print(\"- Feature selection for clustering (numeric + categorical)\")\n",
    "print(\"- Preprocessing pipeline (Robust scaling + one-hot encoding)\")\n",
    "print(\"- PCA analysis (explained variance + component selection)\")\n",
    "print(\"- K-Means model selection (silhouette scores + elbow method)\")\n",
    "print(f\"- Final K-Means clustering fit (k = {BEST_K}) with PCA projection\")\n",
    "print(\"- Cluster profiling (means, sizes, education & marital distributions)\")\n",
    "print(\"- Cluster visualization (2D PCA scatter)\")\n",
    "print(\"- Artifacts saved to /figures, /outputs, and /models\")\n",
    "print(f\"- Final clustering pipeline saved as {model_path.name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
