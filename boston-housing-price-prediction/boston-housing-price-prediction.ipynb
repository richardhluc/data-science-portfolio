{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "396a1cfc-07e9-4045-82c4-35005d837dad",
   "metadata": {},
   "source": [
    "# ===============================================================\n",
    "# Boston Housing Price Prediction\n",
    "# ===============================================================\n",
    "# Goal: Predict median house values (MEDV) in Boston neighborhoods \n",
    "# and produce actionable insights.\n",
    "# Key Tasks:\n",
    "#   1. Explore and visualize the dataset (EDA).\n",
    "#   2. Preprocess & handle missing values.\n",
    "#   3. Train regularized models (Ridge, Lasso) and Polynomial+Ridge.\n",
    "#   4. Perform feature selection (RFE) and explainability (permutation importance).\n",
    "#   5. Compare models using cross-validation and evaluate on a held-out test set.\n",
    "# Tools: Python, pandas, numpy, matplotlib, seaborn, scikit-learn, joblib\n",
    "# Dataset: Kaggle (Boston Housing dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e947bc-2d96-4bd7-a8a6-86d218f7c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- IMPORT LIBRARIES ----------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import math\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612cb978-9eb2-43ad-b4bd-7adc1ce2f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- FEATURE LABELS WITH UNITS ----------\n",
    "feature_labels = {\n",
    "    'CRIM':    'Crime Rate (per capita)',\n",
    "    'ZN':      'Residential Land Zoned (%)',\n",
    "    'INDUS':   'Industrial Land (%)',\n",
    "    'CHAS':    'Charles River Dummy (0/1)',\n",
    "    'NOX':     'Nitric Oxide Concentration (ppm)',\n",
    "    'RM':      'Avg Rooms per Dwelling',\n",
    "    'AGE':     'Pre-1940 Homes (%)',\n",
    "    'DIS':     'Distance to Employment Centers (index)',\n",
    "    'RAD':     'Highway Accessibility (index)',\n",
    "    'TAX':     'Property Tax Rate (per $10k)',\n",
    "    'PTRATIO': 'Pupil–Teacher Ratio',\n",
    "    'B':       'Index of African American Population',\n",
    "    'LSTAT':   'Lower Status Population (%)',\n",
    "    'MEDV':    'Median House Value (1970 USD, $1000s)'\n",
    "}\n",
    "\n",
    "# ---------- PROJECT SETUP ----------\n",
    "project_dir = Path.cwd()\n",
    "\n",
    "fig_dir     = project_dir / \"figures\"\n",
    "models_dir  = project_dir / \"models\"\n",
    "outputs_dir = project_dir / \"outputs\"\n",
    "\n",
    "for d in [fig_dir, models_dir, outputs_dir]:\n",
    "    d.mkdir(exist_ok=True)\n",
    "\n",
    "def save_plot(filename, width=8, height=5, dpi=300):\n",
    "    \"\"\"\n",
    "    Save the current Matplotlib figure into the figures/ folder.\n",
    "    \"\"\"\n",
    "    plt.gcf().set_size_inches(width, height)\n",
    "    plt.savefig(fig_dir / filename, dpi=dpi, bbox_inches=\"tight\")\n",
    "\n",
    "def save_output(df, filename):\n",
    "    \"\"\"\n",
    "    Save a pandas DataFrame into the outputs/ directory as CSV.\n",
    "    \"\"\"\n",
    "    filepath = outputs_dir / filename\n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(f\"Saved output: {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "# -------------------- PLOT STYLE --------------------\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76bf07c-cb8e-48fc-947c-4ccc8d79af7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- LOAD DATA ----------\n",
    "data_path = project_dir / \"boston_housing_data.csv\"\n",
    "\n",
    "boston_df = pd.read_csv(\n",
    "    data_path,\n",
    "    header=None,\n",
    "    sep=r\"\\s+\"\n",
    ")\n",
    "\n",
    "# Column names\n",
    "columns = [\n",
    "    'CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS',\n",
    "    'RAD','TAX','PTRATIO','B','LSTAT','MEDV'\n",
    "]\n",
    "boston_df.columns = columns\n",
    "\n",
    "print(boston_df.head())\n",
    "print(boston_df.isnull().sum())\n",
    "print(boston_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819241cc-f8b5-47c0-a09e-a7e86aa31eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- EXPLORATORY DATA ANALYSIS (EDA) ----------\n",
    "# Histogram: Median House Values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(boston_df['MEDV'], bins=30, edgecolor='black')\n",
    "plt.title('Distribution of Median House Values')\n",
    "plt.xlabel(feature_labels['MEDV'])\n",
    "plt.ylabel('Frequency')\n",
    "save_plot(\"medv_distribution.png\", width=10, height=6, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Scatter Plot: Crime rate vs. Median House Value\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(boston_df['CRIM'], boston_df['MEDV'], alpha=0.5)\n",
    "plt.title('Crime Rate vs. Median House Value')\n",
    "plt.xlabel(feature_labels['CRIM'])\n",
    "plt.ylabel(feature_labels['MEDV'])\n",
    "save_plot(\"crim_vs_medv.png\", width=10, height=6, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Correlation Heatmap\n",
    "corr = boston_df.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "ax = sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True)\n",
    "plt.title(\"Correlation Heatmap of Boston Housing Features\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "save_plot(\"correlation_heatmap.png\", width=12, height=10, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Boxplots of key features\n",
    "features = ['CRIM', 'ZN', 'INDUS', 'RM', 'AGE', 'TAX', 'PTRATIO', 'LSTAT', 'MEDV']\n",
    "n_cols = 3\n",
    "n_features = len(features)\n",
    "n_rows = math.ceil(n_features / n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(features):\n",
    "    sns.boxplot(y=boston_df[col], ax=axes[i])\n",
    "    axes[i].set_title(f\"Boxplot of {col}\")\n",
    "    axes[i].set_ylabel(feature_labels.get(col, col))\n",
    "\n",
    "# Remove unused subplots if features don't fill the grid\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "save_plot(\"boxplots_all_features.png\", width=15, height=n_rows * 4, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Pairplots (selected features)\n",
    "pair = sns.pairplot(\n",
    "    boston_df,\n",
    "    x_vars=['RM', 'LSTAT', 'PTRATIO'],\n",
    "    y_vars='MEDV',\n",
    "    height=4,\n",
    "    kind='scatter'\n",
    ")\n",
    "\n",
    "# Add descriptive axis labels to pairplot\n",
    "for ax in pair.axes.flat:\n",
    "    xlabel = ax.get_xlabel()\n",
    "    ylabel = ax.get_ylabel()\n",
    "    if xlabel in feature_labels:\n",
    "        ax.set_xlabel(feature_labels[xlabel])\n",
    "    if ylabel in feature_labels:\n",
    "        ax.set_ylabel(feature_labels[ylabel])\n",
    "\n",
    "pair.savefig(\n",
    "    fig_dir / \"pairplots_selected.png\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25579af8-5a52-4741-8eb8-94acb228cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- PREPARE FEATURES AND TARGET ----------\n",
    "X = boston_df.drop(columns=['MEDV'])\n",
    "y = boston_df['MEDV'].copy()\n",
    "\n",
    "# Train/test split (80/20)\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, shuffle=True\n",
    ")\n",
    "print(f\"Training rows: {X_train.shape[0]}, Test rows: {X_test.shape[0]}\")\n",
    "\n",
    "# ---------- PREPROCESSING PIPELINE ----------\n",
    "numeric_features = X.columns.tolist()\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_features)\n",
    "], remainder='drop', verbose_feature_names_out=False)\n",
    "\n",
    "# ---------- CROSS-VALIDATION FUNCTION ----------\n",
    "def cv_rmse(estimator, X, y, cv=5):\n",
    "    scores = cross_val_score(estimator, X, y, scoring='neg_root_mean_squared_error', cv=cv)\n",
    "    return -scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef64b7d6-feeb-43e5-9d7e-2d2d42f46097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- TRAIN MODELS ----------\n",
    "# Ridge\n",
    "ridge_pipe = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('ridge', Ridge(random_state=RANDOM_STATE))\n",
    "])\n",
    "ridge_grid = GridSearchCV(\n",
    "    ridge_pipe,\n",
    "    param_grid={'ridge__alpha': [0.1, 1.0, 10.0, 50.0, 100.0]},\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "best_ridge = ridge_grid.best_estimator_\n",
    "ridge_cv_rmse = -ridge_grid.best_score_\n",
    "print(\"Ridge best alpha:\", ridge_grid.best_params_, \"CV RMSE:\", ridge_cv_rmse)\n",
    "\n",
    "# Lasso\n",
    "lasso_pipe = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('lasso', Lasso(max_iter=10000, random_state=RANDOM_STATE))\n",
    "])\n",
    "lasso_grid = GridSearchCV(\n",
    "    lasso_pipe,\n",
    "    param_grid={'lasso__alpha': [0.0001, 0.001, 0.01, 0.1, 1.0]},\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "best_lasso = lasso_grid.best_estimator_\n",
    "lasso_cv_rmse = -lasso_grid.best_score_\n",
    "print(\"Lasso best alpha:\", lasso_grid.best_params_, \"CV RMSE:\", lasso_cv_rmse)\n",
    "\n",
    "# Polynomial Features + Ridge\n",
    "poly_pipe = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('ridge', Ridge(random_state=RANDOM_STATE))\n",
    "])\n",
    "poly_grid = GridSearchCV(\n",
    "    poly_pipe,\n",
    "    param_grid={'ridge__alpha': [0.1, 1.0, 10.0]},\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "poly_grid.fit(X_train, y_train)\n",
    "best_poly = poly_grid.best_estimator_\n",
    "poly_cv_rmse = -poly_grid.best_score_\n",
    "print(\"Poly+Ridge best params:\", poly_grid.best_params_, \"CV RMSE:\", poly_cv_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc2cde3-bbb3-47ca-8b58-6e937becc419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- MODEL COMPARISON ----------\n",
    "cv_summary = pd.DataFrame({\n",
    "    'model': ['Ridge', 'Lasso', 'Poly+Ridge'],\n",
    "    'cv_rmse': [ridge_cv_rmse, lasso_cv_rmse, poly_cv_rmse]\n",
    "}).sort_values('cv_rmse').reset_index(drop=True)\n",
    "\n",
    "print(\"\\nCross-validated RMSE comparison:\\n\", cv_summary)\n",
    "\n",
    "# Save CV summary to outputs\n",
    "save_output(cv_summary, \"cv_rmse_summary.csv\")\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(data=cv_summary, x='model', y='cv_rmse')\n",
    "plt.title(\"Cross-Validated RMSE by Model (Lower is Better)\")\n",
    "plt.ylabel(\"RMSE (MEDV; 1970 USD, $1000s)\")\n",
    "plt.xlabel(\"Model\")\n",
    "save_plot(\"cv_rmse_comparison.png\", width=6, height=4, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# ---------- SELECT BEST MODEL ----------\n",
    "best_model_name = cv_summary.loc[0, 'model']\n",
    "best_model = {\n",
    "    'Ridge': best_ridge,\n",
    "    'Lasso': best_lasso,\n",
    "    'Poly+Ridge': best_poly\n",
    "}[best_model_name]\n",
    "print(\"Selected best model based on CV:\", best_model_name)\n",
    "\n",
    "# Test set evaluation\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "test_rmse = mean_squared_error(y_test, y_pred_test) ** 0.5\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "print(f\"Test RMSE ({best_model_name}): {test_rmse:.2f}\")\n",
    "print(f\"Test R^2 ({best_model_name}): {test_r2:.2f}\")\n",
    "\n",
    "# Save test metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"model\": [best_model_name],\n",
    "    \"test_rmse\": [test_rmse],\n",
    "    \"test_r2\": [test_r2]\n",
    "})\n",
    "save_output(metrics_df, \"test_metrics.csv\")\n",
    "\n",
    "# Save full test-set predictions\n",
    "test_predictions = pd.DataFrame({\n",
    "    \"y_true\": y_test.values,\n",
    "    \"y_pred\": y_pred_test\n",
    "})\n",
    "save_output(test_predictions, \"test_set_predictions.csv\")\n",
    "\n",
    "# Predicted vs True plot\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(y_pred_test, y_test, alpha=0.6)\n",
    "plt.plot(\n",
    "    [y_test.min(), y_test.max()],\n",
    "    [y_test.min(), y_test.max()],\n",
    "    'r--',\n",
    "    lw=2\n",
    ")\n",
    "plt.xlabel(f\"Predicted {feature_labels['MEDV']}\")\n",
    "plt.ylabel(f\"True {feature_labels['MEDV']}\")\n",
    "plt.title(f\"Predicted vs True (Test Set) — {best_model_name}\")\n",
    "save_plot(\"predicted_vs_true.png\", width=7, height=5, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f852e000-05f7-4ee1-b5df-b1d7a6eab62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- FEATURE SELECTION & EXPLAINABILITY ----------\n",
    "# Preprocess train/test\n",
    "X_train_pre = preprocessor.fit_transform(X_train)\n",
    "X_test_pre = preprocessor.transform(X_test)\n",
    "\n",
    "# RFE with LinearRegression\n",
    "lr = LinearRegression()\n",
    "rfe = RFE(estimator=lr, n_features_to_select=6)\n",
    "rfe.fit(X_train_pre, y_train)\n",
    "rfe_selected = [f for f, s in zip(numeric_features, rfe.get_support()) if s]\n",
    "print(\"RFE selected top features (6):\", rfe_selected)\n",
    "\n",
    "rfe_df = pd.DataFrame({\"selected_features\": rfe_selected})\n",
    "save_output(rfe_df, \"rfe_selected_features.csv\")\n",
    "\n",
    "# Permutation importance\n",
    "perm_res = permutation_importance(\n",
    "    best_model,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    n_repeats=20,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "perm_df = pd.DataFrame({\n",
    "    'feature': numeric_features,\n",
    "    'importance_mean': perm_res.importances_mean,\n",
    "    'importance_std': perm_res.importances_std\n",
    "}).sort_values('importance_mean', ascending=False)\n",
    "print(\"\\nPermutation importance (top features):\\n\", perm_df.head(10))\n",
    "\n",
    "save_output(perm_df, \"permutation_importance.csv\")\n",
    "\n",
    "# Top permutation importance plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(\n",
    "    data=perm_df.head(10),\n",
    "    x='importance_mean',\n",
    "    y='feature',\n",
    "    palette='viridis',\n",
    "    legend=False\n",
    ")\n",
    "plt.title(\"Permutation Importance (Test Set)\")\n",
    "plt.xlabel(\"Mean Decrease in Test Score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "save_plot(\"permutation_importance.png\", width=8, height=5, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# --- SAVE BEST MODEL ---\n",
    "model_path = models_dir / \"boston_best_model_refined.pkl\"\n",
    "joblib.dump(best_model, model_path)\n",
    "print(f\"\\nSaved best model to: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014663b4-f4cc-4296-a5d3-a94790b59799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- DEMO PREDICTIONS ----------\n",
    "demo_preds = best_model.predict(X_test.iloc[:5])\n",
    "print(\"Demo predictions (first 5 rows of test set):\", np.round(demo_preds, 2))\n",
    "print(\"Actual values:\", list(y_test.iloc[:5].values))\n",
    "\n",
    "# ---------- PIPELINE COMPLETE ----------\n",
    "print(\"Pipeline complete:\")\n",
    "print(\"- Data loading + EDA (distributions, correlations, pairplots)\")\n",
    "print(\"- Preprocessing (impute + scale) + train/test split\")\n",
    "print(\"- Model training (Ridge, Lasso, Poly+Ridge) with CV tuning\")\n",
    "print(\"- Model selection + test evaluation (RMSE, R^2)\")\n",
    "print(\"- Feature selection (RFE) + explainability (permutation importance)\")\n",
    "print(\"- Artifacts saved to /figures, /outputs, /models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
