{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "315032e6-8c26-4145-811c-73fc689d4df4",
   "metadata": {},
   "source": [
    "# =========================================================================\n",
    "# Restaurant Visitor Demand Forecasting\n",
    "# =========================================================================\n",
    "# Goal: Predict daily restaurant visitors using historical attendance,\n",
    "# calendar effects (day of week, holidays), and restaurant attributes\n",
    "# (genre, location, area).\n",
    "# Key Tasks:\n",
    "#   1. Load & clean data from air_visit_data, air_store_info, date_info.\n",
    "#   2. Fix mojibake (garbled Japanese place names) in text columns.\n",
    "#   3. Explore and visualize visitors over time and by key categories.\n",
    "#   4. Engineer time-based and lag features (previous-day visitors, etc.).\n",
    "#   5. Build preprocessing pipelines for numeric + categorical variables.\n",
    "#   6. Train and compare multiple models (Linear, Ridge, Random Forest).\n",
    "#   7. Evaluate on a time-based validation split and create diagnostics.\n",
    "# Tools: Python, pandas, numpy, matplotlib, seaborn, scikit-learn, joblib\n",
    "# Dataset: Kaggle (Restaurant Visitor dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80d4d2b-cde7-42d0-b7c4-1faa21f80ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- IMPORT LIBRARIES ----------\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b906e76-43bf-4ddf-98dc-0614f2326873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- PROJECT SETUP ----------\n",
    "project_dir = Path.cwd()\n",
    "\n",
    "fig_dir     = project_dir / \"figures\"\n",
    "models_dir  = project_dir / \"models\"\n",
    "outputs_dir = project_dir / \"outputs\"\n",
    "\n",
    "for d in [fig_dir, models_dir, outputs_dir]:\n",
    "    d.mkdir(exist_ok=True)\n",
    "\n",
    "def save_plot(filename, width=8, height=5, dpi=300):\n",
    "    \"\"\"Save the current Matplotlib figure into figures/.\"\"\"\n",
    "    plt.gcf().set_size_inches(width, height)\n",
    "    plt.savefig(fig_dir / filename, dpi=dpi, bbox_inches=\"tight\")\n",
    "\n",
    "def save_output(df, filename):\n",
    "    \"\"\"Save a pandas DataFrame into outputs/ as CSV.\"\"\"\n",
    "    filepath = outputs_dir / filename\n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(f\"Saved output: {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "# -------------------- PLOT STYLE --------------------\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rc(\"font\", size=12)\n",
    "plt.rc(\"axes\", labelsize=12, titlesize=13)\n",
    "plt.rc(\"legend\", fontsize=10)\n",
    "plt.rc(\"xtick\", labelsize=10)\n",
    "plt.rc(\"ytick\", labelsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf7d90d-1a48-43ce-b6b2-47fb70654f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- LOAD DATA --------------------\n",
    "air_visit_path = project_dir / \"air_visit_data.csv\"\n",
    "air_store_path = project_dir / \"air_store_info.csv\"\n",
    "date_info_path = project_dir / \"date_info.csv\"\n",
    "\n",
    "air_visit = pd.read_csv(air_visit_path)\n",
    "air_store = pd.read_csv(air_store_path)\n",
    "date_info = pd.read_csv(date_info_path)\n",
    "\n",
    "print(\"air_visit_data head:\")\n",
    "print(air_visit.head(), \"\\n\")\n",
    "print(\"air_store_info head:\")\n",
    "print(air_store.head(), \"\\n\")\n",
    "print(\"date_info head:\")\n",
    "print(date_info.head(), \"\\n\")\n",
    "\n",
    "print(\"air_visit_data info:\")\n",
    "print(air_visit.info(), \"\\n\")\n",
    "print(\"air_store_info info:\")\n",
    "print(air_store.info(), \"\\n\")\n",
    "print(\"date_info info:\")\n",
    "print(date_info.info(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e335d05-1f5e-426b-a034-b21d8f6dfa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- FIX MOJIBAKE (GARBLED TEXT IN AREA/GENRE NAMES) ----------\n",
    "def fix_mojibake(text):\n",
    "    \"\"\"\n",
    "    Fix UTF-8 text that was incorrectly decoded as Latin-1.\n",
    "    If conversion fails, return the original text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return text.encode(\"latin1\").decode(\"utf8\")\n",
    "    except Exception:\n",
    "        return text\n",
    "\n",
    "air_store[\"air_area_name\"] = air_store[\"air_area_name\"].astype(str).apply(fix_mojibake)\n",
    "air_store[\"air_genre_name\"] = air_store[\"air_genre_name\"].astype(str).apply(fix_mojibake)\n",
    "\n",
    "print(\"Unique air_area_name samples after mojibake fix:\")\n",
    "print(air_store[\"air_area_name\"].drop_duplicates().head(15), \"\\n\")\n",
    "\n",
    "# ---------- MERGE DATASETS ----------\n",
    "# Convert dates\n",
    "air_visit[\"visit_date\"] = pd.to_datetime(air_visit[\"visit_date\"])\n",
    "date_info[\"calendar_date\"] = pd.to_datetime(date_info[\"calendar_date\"])\n",
    "\n",
    "# Rename calendar_date to visit_date\n",
    "date_info_renamed = date_info.rename(columns={\"calendar_date\": \"visit_date\"})\n",
    "\n",
    "# Merge: visit data + store info + calendar\n",
    "df = (\n",
    "    air_visit\n",
    "    .merge(air_store, on=\"air_store_id\", how=\"left\")\n",
    "    .merge(date_info_renamed, on=\"visit_date\", how=\"left\")\n",
    ")\n",
    "\n",
    "df = df.sort_values([\"air_store_id\", \"visit_date\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"Merged dataset head:\")\n",
    "print(df.head(), \"\\n\")\n",
    "print(\"Merged dataset info:\")\n",
    "print(df.info(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080b6048-f8b6-4c1c-9c58-f09d6b624a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- EXPLORATORY DATA ANALYSIS (EDA) ----------\n",
    "print(\"Descriptive statistics for visitors:\")\n",
    "print(df[\"visitors\"].describe(), \"\\n\")\n",
    "\n",
    "# --- Histogram of visitors (zoom to 99th percentile) ---\n",
    "upper_vis = df[\"visitors\"].quantile(0.99)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(df[\"visitors\"], bins=40, range=(0, upper_vis), edgecolor=\"black\")\n",
    "plt.title(\"Distribution of Daily Visitors (0–99th percentile)\")\n",
    "plt.xlabel(\"Visitors (count per day)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "save_plot(\"visitors_histogram.png\", width=12, height=5, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Visitors by day of week\n",
    "visitors_by_dow = df.groupby(\"day_of_week\")[\"visitors\"].mean().reindex(\n",
    "    [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "visitors_by_dow.plot(kind=\"bar\")\n",
    "plt.title(\"Average Visitors by Day of Week\")\n",
    "plt.xlabel(\"Day of Week\")\n",
    "plt.ylabel(\"Average Visitors\")\n",
    "plt.tight_layout()\n",
    "save_plot(\"visitors_by_day_of_week.png\")\n",
    "plt.show()\n",
    "\n",
    "# Visitors by holiday flag\n",
    "plt.figure()\n",
    "df.groupby(\"holiday_flg\")[\"visitors\"].mean().plot(kind=\"bar\")\n",
    "plt.title(\"Average Visitors: Holiday vs Non-Holiday\")\n",
    "plt.xlabel(\"holiday_flg (0 = Non-Holiday, 1 = Holiday)\")\n",
    "plt.ylabel(\"Average Visitors\")\n",
    "plt.tight_layout()\n",
    "save_plot(\"visitors_by_holiday.png\")\n",
    "plt.show()\n",
    "\n",
    "# Top restaurant genres\n",
    "top_genres = df[\"air_genre_name\"].value_counts().head(10)\n",
    "\n",
    "plt.figure()\n",
    "top_genres.plot(kind=\"bar\")\n",
    "plt.title(\"Top 10 Restaurant Genres (Count of Records)\")\n",
    "plt.xlabel(\"Genre\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "save_plot(\"top_genres_count.png\", width=9, height=5, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Overall time series of average visitors across all stores\n",
    "daily_visitors = df.groupby(\"visit_date\")[\"visitors\"].mean()\n",
    "\n",
    "plt.figure()\n",
    "daily_visitors.plot()\n",
    "plt.title(\"Average Daily Visitors Over Time (All Stores)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average Visitors\")\n",
    "plt.tight_layout()\n",
    "save_plot(\"avg_daily_visitors_over_time.png\", width=10, height=5, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7b0460-42e2-417a-8718-3be038bf2fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- FEATURE ENGINEERING ----------\n",
    "df[\"year\"] = df[\"visit_date\"].dt.year\n",
    "df[\"month\"] = df[\"visit_date\"].dt.month\n",
    "df[\"day\"] = df[\"visit_date\"].dt.day\n",
    "df[\"dayofweek_num\"] = df[\"visit_date\"].dt.dayofweek \n",
    "df[\"is_weekend\"] = df[\"dayofweek_num\"].isin([5, 6]).astype(int)\n",
    "\n",
    "# Lag features: previous-day visitors & 7-day lag, plus 7-day rolling mean\n",
    "df = df.sort_values([\"air_store_id\", \"visit_date\"])\n",
    "\n",
    "df[\"visitors_lag1\"] = df.groupby(\"air_store_id\")[\"visitors\"].shift(1)\n",
    "df[\"visitors_lag7\"] = df.groupby(\"air_store_id\")[\"visitors\"].shift(7)\n",
    "df[\"visitors_roll7\"] = (\n",
    "    df.groupby(\"air_store_id\")[\"visitors\"]\n",
    "    .shift(1)\n",
    "    .rolling(window=7, min_periods=1)\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "feature_cols = [\n",
    "    \"visit_date\",\n",
    "    \"air_store_id\",\n",
    "    \"visitors\",\n",
    "    \"year\", \"month\", \"day\", \"dayofweek_num\", \"is_weekend\",\n",
    "    \"holiday_flg\",\n",
    "    \"latitude\", \"longitude\",\n",
    "    \"visitors_lag1\", \"visitors_lag7\", \"visitors_roll7\",\n",
    "    \"air_genre_name\", \"air_area_name\", \"day_of_week\"\n",
    "]\n",
    "\n",
    "df_model = df[feature_cols].dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"Modeling dataset shape after lag feature creation and dropna:\", df_model.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26500093-7c66-4655-80d8-4f878a8f5f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- TRAIN / VALIDATION SPLIT (TIME-BASED) ----------\n",
    "split_date = df_model[\"visit_date\"].quantile(0.8)\n",
    "train_mask = df_model[\"visit_date\"] <= split_date\n",
    "valid_mask = df_model[\"visit_date\"] > split_date\n",
    "\n",
    "train_df = df_model[train_mask].copy()\n",
    "valid_df = df_model[valid_mask].copy()\n",
    "\n",
    "print(\"Train date range:\", train_df[\"visit_date\"].min(), \"->\", train_df[\"visit_date\"].max())\n",
    "print(\"Valid date range:\", valid_df[\"visit_date\"].min(), \"->\", valid_df[\"visit_date\"].max(), \"\\n\")\n",
    "\n",
    "target_col = \"visitors\"\n",
    "\n",
    "drop_cols = [\"visit_date\", \"air_store_id\", target_col]\n",
    "\n",
    "X_train = train_df.drop(columns=drop_cols)\n",
    "y_train = train_df[target_col]\n",
    "\n",
    "X_valid = valid_df.drop(columns=drop_cols)\n",
    "y_valid = valid_df[target_col]\n",
    "\n",
    "numeric_features = [\n",
    "    \"year\", \"month\", \"day\", \"dayofweek_num\", \"is_weekend\",\n",
    "    \"holiday_flg\", \"latitude\", \"longitude\",\n",
    "    \"visitors_lag1\", \"visitors_lag7\", \"visitors_roll7\"\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"air_genre_name\",\n",
    "    \"air_area_name\",\n",
    "    \"day_of_week\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74e1af-648d-407b-9bc7-ae94575a2167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- PREPROCESSING PIPELINE ----------\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4743ead-dba0-4a36-a0b0-833ea95dd984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- MODEL TRAINING & EVALUATION ----------\n",
    "models = [\n",
    "    (\"LinearRegression\", LinearRegression()),\n",
    "    (\"Ridge\", Ridge(alpha=1.0, random_state=None)),\n",
    "    (\"RandomForest\", RandomForestRegressor(\n",
    "        n_estimators=150,\n",
    "        max_depth=12,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "]\n",
    "\n",
    "results = []\n",
    "fitted_pipelines = {}\n",
    "\n",
    "for name, model in models:\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    pipeline = Pipeline(steps=[\n",
    "        (\"preprocess\", preprocessing),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_valid_pred = pipeline.predict(X_valid)\n",
    "\n",
    "    train_rmse = rmse(y_train, y_train_pred)\n",
    "    valid_rmse = rmse(y_valid, y_valid_pred)\n",
    "    valid_r2 = r2_score(y_valid, y_valid_pred)\n",
    "\n",
    "    print(f\"{name} - Train RMSE: {train_rmse:.3f}\")\n",
    "    print(f\"{name} - Valid RMSE: {valid_rmse:.3f}\")\n",
    "    print(f\"{name} - Valid R²:   {valid_r2:.3f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"model\": name,\n",
    "        \"train_rmse\": train_rmse,\n",
    "        \"valid_rmse\": valid_rmse,\n",
    "        \"valid_r2\": valid_r2\n",
    "    })\n",
    "\n",
    "    fitted_pipelines[name] = (pipeline, y_valid_pred)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nModel performance summary:\")\n",
    "print(results_df, \"\\n\")\n",
    "\n",
    "save_output(results_df, \"model_performance_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c555afd0-4066-493a-adc5-f1fb837c4c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- DIAGNOSTIC PLOTS FOR BEST MODEL ----------\n",
    "best_row = results_df.loc[results_df[\"valid_rmse\"].idxmin()]\n",
    "best_model_name = best_row[\"model\"]\n",
    "best_pipeline, best_valid_pred = fitted_pipelines[best_model_name]\n",
    "\n",
    "print(f\"Best model based on validation RMSE: {best_model_name}\")\n",
    "\n",
    "# Predicted vs True scatter (zoomed)\n",
    "plt.figure()\n",
    "plt.scatter(y_valid, best_valid_pred, alpha=0.3)\n",
    "plt.xlim(0, 150)\n",
    "plt.ylim(0, 150)\n",
    "plt.plot([0, 150], [0, 150], \"r--\", linewidth=2)\n",
    "plt.xlabel(\"True Visitors\")\n",
    "plt.ylabel(\"Predicted Visitors\")\n",
    "plt.title(f\"{best_model_name} - Predicted vs True Visitors (Validation, Zoomed)\")\n",
    "plt.tight_layout()\n",
    "save_plot(f\"{best_model_name}_pred_vs_true_zoomed.png\", width=7, height=6, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# --- Residual histogram (zoom to 99th percentile of |residuals|) ---\n",
    "residuals = y_valid - best_valid_pred\n",
    "res_cap = np.quantile(np.abs(residuals), 0.99)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(residuals, bins=40, range=(-res_cap, res_cap), edgecolor=\"black\")\n",
    "plt.title(f\"{best_model_name} - Residuals Distribution (Validation, ±99th pct)\")\n",
    "plt.xlabel(\"Residual (True - Predicted visitors)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "save_plot(f\"{best_model_name}_residuals_hist.png\", width=10, height=6, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Time plot of actual vs predicted (validation period, averaged across stores)\n",
    "valid_df_plot = valid_df.copy()\n",
    "valid_df_plot[\"predicted_visitors\"] = best_valid_pred\n",
    "\n",
    "daily_actual = valid_df_plot.groupby(\"visit_date\")[\"visitors\"].mean()\n",
    "daily_pred = valid_df_plot.groupby(\"visit_date\")[\"predicted_visitors\"].mean()\n",
    "\n",
    "plt.figure()\n",
    "daily_actual.plot(label=\"Actual\", linewidth=2)\n",
    "daily_pred.plot(label=\"Predicted\", linewidth=2)\n",
    "plt.title(f\"{best_model_name} - Average Visitors Over Time (Validation)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average Visitors\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "save_plot(f\"{best_model_name}_daily_actual_vs_pred.png\", width=10, height=5, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752caec3-efc8-4b40-9951-8620229dc85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- FIT BEST MODEL ON FULL DATA ----------\n",
    "X_full = df_model.drop(columns=drop_cols)\n",
    "y_full = df_model[target_col]\n",
    "\n",
    "best_pipeline.fit(X_full, y_full)\n",
    "\n",
    "# --- SAVE BEST MODEL ---\n",
    "model_path = models_dir / \"restaurant_visitors_best_model.pkl\"\n",
    "joblib.dump(best_pipeline, model_path)\n",
    "print(f\"\\nSaved best model to: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2155a624-0b0c-4990-8075-4dd51c4724af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- DEMO PREDICTIONS ----------\n",
    "demo_sample = X_valid.head(5)\n",
    "demo_preds = best_pipeline.predict(demo_sample)\n",
    "\n",
    "print(\"\\nDemo predictions (first 5 validation rows):\")\n",
    "print(\"Predicted:\", np.round(demo_preds, 2))\n",
    "print(\"Actual   :\", np.round(y_valid.head(5).values, 2))\n",
    "\n",
    "# -------------------- PIPELINE COMPLETE --------------------\n",
    "print(\"\\nPipeline complete:\")\n",
    "print(\"- Project setup (figures/, outputs/, models/ directories)\")\n",
    "print(\"- Data loading & validation (air_visit_data, air_store_info, date_info)\")\n",
    "print(\"- Text cleaning (mojibake fix for area/genre names)\")\n",
    "print(\"- Dataset merge (visits + store metadata + calendar)\")\n",
    "print(\"- Exploratory analysis (visitor distributions, seasonality, holidays, genres)\")\n",
    "print(\"- Feature engineering (date parts, weekend flag, lag & rolling features)\")\n",
    "print(\"- Time-based train/validation split\")\n",
    "print(\"- Preprocessing pipeline (StandardScaler + OneHotEncoder)\")\n",
    "print(\"- Model training & comparison (Linear, Ridge, Random Forest)\")\n",
    "print(\"- Evaluation on validation set (RMSE, R², diagnostics plots)\")\n",
    "print(\"- Best model refit on full dataset\")\n",
    "print(f\"- Final regression pipeline saved as {model_path.name}\")\n",
    "print(\"- All artifacts saved to /figures, /outputs, and /models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
