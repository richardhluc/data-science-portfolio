{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40707ddc-c8f4-4051-8584-a755ab42a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# Student Academic Success Prediction\n",
    "# ======================================================\n",
    "# Goal: Predict final math grades (G3) for secondary students and\n",
    "# understand how demographics, family context, and school-related factors\n",
    "# contribute to academic performance.\n",
    "# Key Tasks:\n",
    "#   1. Explore and visualize the student performance data.\n",
    "#   2. Handle missing values and encode categorical/ordinal variables.\n",
    "#   3. Use statistical tests (correlation + ANOVA) to select relevant features.\n",
    "#   4. Engineer an absences_sum feature and build pipelines with and without\n",
    "#      prior term grades (G1, G2).\n",
    "#   5. Train and compare multiple models (Linear, Lasso, SVR).\n",
    "#   6. Fine-tune SVR using GridSearchCV.\n",
    "#   7. Evaluate the best model on a held-out test set (RMSE, MAE, R²).\n",
    "#   8. Derive an “at-risk student” classification view from the regression model.\n",
    "# Tools: Python, pandas, numpy, matplotlib, seaborn, scikit-learn, joblib\n",
    "# Dataset: UCI Machine Learning Repository (Student Performance dataset)\n",
    "\n",
    "# -------------------- IMPORT LIBRARIES --------------------\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    mean_absolute_error,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- PROJECT SETUP ----------\n",
    "project_dir = Path.cwd()\n",
    "\n",
    "fig_dir     = project_dir / \"figures\"\n",
    "models_dir  = project_dir / \"models\"\n",
    "outputs_dir = project_dir / \"outputs\"\n",
    "\n",
    "for d in [fig_dir, models_dir, outputs_dir]:\n",
    "    d.mkdir(exist_ok=True)\n",
    "\n",
    "def save_plot(filename, width=8, height=5, dpi=300):\n",
    "    \"\"\"\n",
    "    Save the current Matplotlib figure into the figures/ folder.\n",
    "    \"\"\"\n",
    "    plt.gcf().set_size_inches(width, height)\n",
    "    plt.savefig(fig_dir / filename, dpi=dpi, bbox_inches=\"tight\")\n",
    "\n",
    "def save_output(df, filename):\n",
    "    \"\"\"\n",
    "    Save a pandas DataFrame into the outputs/ directory as CSV.\n",
    "    \"\"\"\n",
    "    filepath = outputs_dir / filename\n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(f\"Saved output: {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "# ---------- LABELS / UNITS FOR NUMERIC FEATURES ----------\n",
    "numeric_feature_labels = {\n",
    "    \"age\": \"Age (years)\",\n",
    "    \"absences_G1\": \"Absences in Period 1\",\n",
    "    \"absences_G2\": \"Absences in Period 2\",\n",
    "    \"absences_G3\": \"Absences in Period 3\",\n",
    "    \"G1\": \"Grade Period 1 (0–20)\",\n",
    "    \"G2\": \"Grade Period 2 (0–20)\",\n",
    "    \"G3\": \"Final Grade G3 (0–20)\",\n",
    "}\n",
    "\n",
    "# -------------------- PLOT STYLE --------------------\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rc(\"font\", size=14)\n",
    "plt.rc(\"axes\", labelsize=14, titlesize=14)\n",
    "plt.rc(\"legend\", fontsize=12)\n",
    "plt.rc(\"xtick\", labelsize=10)\n",
    "plt.rc(\"ytick\", labelsize=10)\n",
    "\n",
    "# -------------------- LOAD DATA --------------------\n",
    "data_path = project_dir / \"student_academic_success_data.csv\"\n",
    "\n",
    "student_df = pd.read_csv(data_path)\n",
    "\n",
    "print(\"Dataset shape:\", student_df.shape, \"\\n\")\n",
    "print(\"First 5 rows:\\n\", student_df.head(), \"\\n\")\n",
    "print(\"Info:\\n\")\n",
    "student_df.info()\n",
    "print(\"\\nMissing values per column:\\n\", student_df.isna().sum(), \"\\n\")\n",
    "\n",
    "# Copy for EDA + imputation\n",
    "student_df_copy = student_df.copy()\n",
    "\n",
    "# -------------------- COLUMN GROUPING --------------------\n",
    "numeric_columns_full = [\"age\", \"absences_G1\", \"absences_G2\", \"absences_G3\", \"G1\", \"G2\", \"G3\"]\n",
    "\n",
    "categorical_columns_full = [\n",
    "    \"school\", \"sex\", \"address\", \"famsize\", \"Pstatus\",\n",
    "    \"Mjob\", \"Fjob\", \"reason\", \"guardian\",\n",
    "    \"schoolsup\", \"famsup\", \"paid\", \"activities\",\n",
    "    \"nursery\", \"higher\", \"internet\", \"romantic\",\n",
    "]\n",
    "\n",
    "ordinal_columns_full = [\n",
    "    \"Medu\", \"Fedu\", \"traveltime\", \"studytime\", \"failures\",\n",
    "    \"famrel\", \"freetime\", \"goout\", \"Dalc\", \"Walc\", \"health\",\n",
    "]\n",
    "\n",
    "# Impute missing values for EDA only\n",
    "num_imputer_eda = SimpleImputer(strategy=\"mean\")\n",
    "student_df_copy[numeric_columns_full] = num_imputer_eda.fit_transform(\n",
    "    student_df_copy[numeric_columns_full]\n",
    ")\n",
    "\n",
    "cat_imputer_eda = SimpleImputer(strategy=\"most_frequent\")\n",
    "student_df_copy[categorical_columns_full] = cat_imputer_eda.fit_transform(\n",
    "    student_df_copy[categorical_columns_full]\n",
    ")\n",
    "\n",
    "ord_imputer_eda = SimpleImputer(strategy=\"most_frequent\")\n",
    "student_df_copy[ordinal_columns_full] = ord_imputer_eda.fit_transform(\n",
    "    student_df_copy[ordinal_columns_full]\n",
    ")\n",
    "\n",
    "print(\"Remaining missing values after EDA imputations:\\n\",\n",
    "      student_df_copy.isna().sum(), \"\\n\")\n",
    "\n",
    "# -------------------- EXPLORATORY DATA ANALYSIS (EDA) --------------------\n",
    "# Numeric stats\n",
    "numeric_stats = student_df_copy[numeric_columns_full].describe()\n",
    "print(\"\\nNumeric summary statistics:\\n\", numeric_stats, \"\\n\")\n",
    "save_output(numeric_stats.reset_index(), \"numeric_summary_stats.csv\")\n",
    "\n",
    "# ---- Histograms for numeric columns ----\n",
    "fig, axes = plt.subplots(3, 3, figsize=(14, 9))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, col in zip(axes, numeric_columns_full):\n",
    "    ax.hist(student_df_copy[col], bins=20)\n",
    "    ax.set_title(col)\n",
    "    ax.set_xlabel(numeric_feature_labels.get(col, col))\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "# Remove any unused subplots\n",
    "for j in range(len(numeric_columns_full), len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "fig.suptitle(\"Numeric Feature Distributions\", y=1.02)\n",
    "plt.tight_layout()\n",
    "save_plot(\"hist_numeric.png\", width=14, height=9, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Categorical stats\n",
    "categorical_stats = student_df_copy[categorical_columns_full].describe(include=\"object\")\n",
    "print(\"\\nCategorical summary statistics:\\n\", categorical_stats, \"\\n\")\n",
    "save_output(categorical_stats.reset_index(), \"categorical_summary_stats.csv\")\n",
    "\n",
    "# Ordinal stats\n",
    "ordinal_stats = student_df_copy[ordinal_columns_full].describe()\n",
    "print(\"\\nOrdinal summary statistics:\\n\", ordinal_stats, \"\\n\")\n",
    "save_output(ordinal_stats.reset_index(), \"ordinal_summary_stats.csv\")\n",
    "\n",
    "# -------------------- CORRELATION ANALYSIS (NUMERIC) --------------------\n",
    "corr_matrix = student_df_copy[numeric_columns_full].corr()\n",
    "print(\"\\nCorrelation matrix (numeric features):\\n\", corr_matrix, \"\\n\")\n",
    "print(\"\\nCorrelation of numeric features with G3:\\n\",\n",
    "      corr_matrix[\"G3\"].sort_values(ascending=False), \"\\n\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True)\n",
    "plt.title(\"Correlation Heatmap — Numeric Features\")\n",
    "plt.tight_layout()\n",
    "save_plot(\"correlation_heatmap_numeric.png\", width=8, height=6, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "save_output(corr_matrix.reset_index(), \"correlation_matrix_numeric.csv\")\n",
    "\n",
    "# -------------------- ANOVA FOR CATEGORICAL & ORDINAL FEATURES --------------------\n",
    "anova_results = {}\n",
    "\n",
    "for col in categorical_columns_full + ordinal_columns_full:\n",
    "    if col in ordinal_columns_full:\n",
    "        levels = sorted(student_df_copy[col].unique())\n",
    "    else:\n",
    "        levels = student_df_copy[col].unique()\n",
    "\n",
    "    grouped = [student_df_copy[student_df_copy[col] == level][\"G3\"] for level in levels]\n",
    "    f_stat, p_value = f_oneway(*grouped)\n",
    "    anova_results[col] = {\"F-statistic\": f_stat, \"p-value\": p_value}\n",
    "\n",
    "    # Plot only statistically significant features\n",
    "    if p_value < 0.05:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.boxplot(x=col, y=\"G3\", data=student_df_copy, palette=\"viridis\")\n",
    "        plt.title(f\"G3 by {col} (ANOVA Significant)\")\n",
    "        f_text = f\"F-stat: {f_stat:.2f}\"\n",
    "        p_text = f\"p-value: {p_value:.3f}\"\n",
    "        plt.text(\n",
    "            0.5,\n",
    "            0.9,\n",
    "            f_text + \"\\n\" + p_text,\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            transform=plt.gca().transAxes,\n",
    "            fontsize=12,\n",
    "            color=\"black\",\n",
    "            bbox=dict(facecolor=\"white\", alpha=0.7),\n",
    "        )\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(\"Final Grade (G3, 0–20)\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        save_plot(f\"boxplot_G3_by_{col}.png\", width=10, height=6, dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "print(\"\\nANOVA results (F-statistic, p-value) — sample:\\n\")\n",
    "for k, v in list(anova_results.items())[:5]:\n",
    "    print(k, \"->\", v)\n",
    "\n",
    "anova_df = (\n",
    "    pd.DataFrame.from_dict(anova_results, orient=\"index\")\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"feature\"})\n",
    ")\n",
    "save_output(anova_df, \"anova_results_G3.csv\")\n",
    "\n",
    "# -------------------- DEFINE FEATURES FOR MODELING --------------------\n",
    "# Based on significance & domain logic\n",
    "numeric_model_columns = [\"age\", \"absences_G1\", \"absences_G2\", \"absences_G3\", \"G1\", \"G2\"]\n",
    "categorical_model_columns = [\"sex\", \"address\", \"Mjob\", \"paid\", \"higher\", \"romantic\"]\n",
    "ordinal_model_columns = [\"Medu\", \"Fedu\", \"failures\", \"goout\"]\n",
    "\n",
    "# Target and features\n",
    "X = student_df.drop(\"G3\", axis=1)\n",
    "y = student_df[\"G3\"].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nX_train missing values:\\n\", X_train.isna().sum(), \"\\n\")\n",
    "\n",
    "# -------------------- CUSTOM TRANSFORMER - ABSENCE FEATURE ENGINEERING --------------------\n",
    "class FinalProjectTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Adds absences_sum = absences_G1 + absences_G2 + absences_G3\n",
    "    Optionally drops G1, G2 (for models that do not use prior grades).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, drop_grades=False):\n",
    "        self.drop_grades = drop_grades\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        X_transformed[\"absences_sum\"] = (\n",
    "            X_transformed[\"absences_G1\"]\n",
    "            + X_transformed[\"absences_G2\"]\n",
    "            + X_transformed[\"absences_G3\"]\n",
    "        )\n",
    "        X_transformed.drop([\"absences_G1\", \"absences_G2\", \"absences_G3\"], axis=1, inplace=True)\n",
    "        if self.drop_grades:\n",
    "            X_transformed.drop([\"G1\", \"G2\"], axis=1, inplace=True)\n",
    "        return X_transformed\n",
    "\n",
    "# -------------------- PIPELINES & COLUMN TRANSFORMERS --------------------\n",
    "# Imputer that returns DataFrame\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "imputer.set_output(transform=\"pandas\")\n",
    "\n",
    "# Numeric pipeline WITH grades (G1, G2 kept)\n",
    "numeric_pipeline_with_grades = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", imputer),\n",
    "        (\"feature_engineering\", FinalProjectTransformer(drop_grades=False)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Numeric pipeline WITHOUT grades (G1, G2 removed)\n",
    "numeric_pipeline_without_grades = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", imputer),\n",
    "        (\"feature_engineering\", FinalProjectTransformer(drop_grades=True)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Categorical pipeline\n",
    "categorical_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"),\n",
    ")\n",
    "\n",
    "# Ordinal pipeline\n",
    "ordinal_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OrdinalEncoder(),\n",
    ")\n",
    "\n",
    "# Column transformer WITH grades\n",
    "column_transformer_with_grades = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipeline_with_grades, numeric_model_columns),\n",
    "        (\"cat\", categorical_pipeline, categorical_model_columns),\n",
    "        (\"ord\", ordinal_pipeline, ordinal_model_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Column transformer WITHOUT grades\n",
    "column_transformer_without_grades = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipeline_without_grades, numeric_model_columns),\n",
    "        (\"cat\", categorical_pipeline, categorical_model_columns),\n",
    "        (\"ord\", ordinal_pipeline, ordinal_model_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit-transform on train\n",
    "X_train_transformed_with = column_transformer_with_grades.fit_transform(X_train)\n",
    "X_train_transformed_without = column_transformer_without_grades.fit_transform(X_train)\n",
    "\n",
    "print(\"Transformed shape WITH grades:\", X_train_transformed_with.shape)\n",
    "print(\"Transformed shape WITHOUT grades:\", X_train_transformed_without.shape)\n",
    "\n",
    "# -------------------- BASELINE MODEL COMPARISON (CV) --------------------\n",
    "lin_reg = LinearRegression()\n",
    "svm_reg = SVR()\n",
    "lasso_reg = Lasso()\n",
    "\n",
    "results = []\n",
    "\n",
    "def cv_rmse(model, X, y, label):\n",
    "    scores = cross_val_score(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=3,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "    )\n",
    "    mean_rmse = -scores.mean()\n",
    "    print(f\"{label} — CV RMSE: {mean_rmse:.3f}\")\n",
    "    return mean_rmse\n",
    "\n",
    "# Linear Regression\n",
    "rmse_lin_with = cv_rmse(lin_reg, X_train_transformed_with, y_train, \"Linear Regression (with grades)\")\n",
    "rmse_lin_without = cv_rmse(lin_reg, X_train_transformed_without, y_train, \"Linear Regression (without grades)\")\n",
    "results.append({\"model\": \"Linear (with grades)\", \"cv_rmse\": rmse_lin_with})\n",
    "results.append({\"model\": \"Linear (without grades)\", \"cv_rmse\": rmse_lin_without})\n",
    "\n",
    "# SVR (default hyperparameters)\n",
    "rmse_svm_with = cv_rmse(svm_reg, X_train_transformed_with, y_train, \"SVR (with grades)\")\n",
    "rmse_svm_without = cv_rmse(svm_reg, X_train_transformed_without, y_train, \"SVR (without grades)\")\n",
    "results.append({\"model\": \"SVR (with grades)\", \"cv_rmse\": rmse_svm_with})\n",
    "results.append({\"model\": \"SVR (without grades)\", \"cv_rmse\": rmse_svm_without})\n",
    "\n",
    "# Lasso\n",
    "rmse_lasso_with = cv_rmse(lasso_reg, X_train_transformed_with, y_train, \"Lasso (with grades)\")\n",
    "rmse_lasso_without = cv_rmse(lasso_reg, X_train_transformed_without, y_train, \"Lasso (without grades)\")\n",
    "results.append({\"model\": \"Lasso (with grades)\", \"cv_rmse\": rmse_lasso_with})\n",
    "results.append({\"model\": \"Lasso (without grades)\", \"cv_rmse\": rmse_lasso_without})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nCross-validated RMSE comparison:\\n\", results_df, \"\\n\")\n",
    "save_output(results_df, \"cv_rmse_summary_students.csv\")\n",
    "\n",
    "# -------------------- HYPERPARAMETER TUNING - SVR --------------------\n",
    "param_grid = {\n",
    "    \"C\": [0.1, 1, 10],\n",
    "    \"kernel\": [\"linear\", \"rbf\"],\n",
    "    \"gamma\": [\"scale\", \"auto\"],\n",
    "    \"epsilon\": [0.1, 0.2, 0.3],\n",
    "}\n",
    "\n",
    "svm_reg = SVR()\n",
    "\n",
    "# WITH grades\n",
    "grid_search_with = GridSearchCV(\n",
    "    svm_reg,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "grid_search_with.fit(X_train_transformed_with, y_train)\n",
    "\n",
    "best_params_with = grid_search_with.best_params_\n",
    "best_score_with = -grid_search_with.best_score_  # positive RMSE\n",
    "\n",
    "print(\"Best SVR params (WITH grades):\", best_params_with)\n",
    "print(f\"Best CV RMSE (WITH grades): {best_score_with:.3f}\\n\")\n",
    "\n",
    "# WITHOUT grades\n",
    "grid_search_without = GridSearchCV(\n",
    "    svm_reg,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "grid_search_without.fit(X_train_transformed_without, y_train)\n",
    "\n",
    "best_params_without = grid_search_without.best_params_\n",
    "best_score_without = -grid_search_without.best_score_\n",
    "\n",
    "print(\"Best SVR params (WITHOUT grades):\", best_params_without)\n",
    "print(f\"Best CV RMSE (WITHOUT grades): {best_score_without:.3f}\\n\")\n",
    "\n",
    "# -------------------- FINAL MODELS & TEST EVALUATION --------------------\n",
    "# Build final models using best params from GridSearch\n",
    "best_svm_with = SVR(**best_params_with)\n",
    "best_svm_without = SVR(**best_params_without)\n",
    "\n",
    "best_svm_with.fit(X_train_transformed_with, y_train)\n",
    "best_svm_without.fit(X_train_transformed_without, y_train)\n",
    "\n",
    "# Transform test set\n",
    "X_test_transformed_with = column_transformer_with_grades.transform(X_test)\n",
    "X_test_transformed_without = column_transformer_without_grades.transform(X_test)\n",
    "\n",
    "# Predictions\n",
    "y_pred_with = best_svm_with.predict(X_test_transformed_with)\n",
    "y_pred_without = best_svm_without.predict(X_test_transformed_without)\n",
    "\n",
    "# Metrics\n",
    "rmse_with = np.sqrt(mean_squared_error(y_test, y_pred_with))\n",
    "rmse_without = np.sqrt(mean_squared_error(y_test, y_pred_without))\n",
    "\n",
    "r2_with = r2_score(y_test, y_pred_with)\n",
    "r2_without = r2_score(y_test, y_pred_without)\n",
    "\n",
    "mae_with = mean_absolute_error(y_test, y_pred_with)\n",
    "mae_without = mean_absolute_error(y_test, y_pred_without)\n",
    "\n",
    "print(\"=== Final SVR Model Performance (Test Set) ===\")\n",
    "print(f\"WITH grades:    RMSE = {rmse_with:.2f}, MAE = {mae_with:.2f}, R² = {r2_with:.3f}\")\n",
    "print(f\"WITHOUT grades: RMSE = {rmse_without:.2f}, MAE = {mae_without:.2f}, R² = {r2_without:.3f}\\n\")\n",
    "\n",
    "# Comparison DataFrame\n",
    "metrics_df = pd.DataFrame(\n",
    "    {\n",
    "        \"setting\": [\"With grades\", \"Without grades\"],\n",
    "        \"rmse\": [rmse_with, rmse_without],\n",
    "        \"mae\": [mae_with, mae_without],\n",
    "        \"r2\": [r2_with, r2_without],\n",
    "    }\n",
    ")\n",
    "print(\"Metrics comparison:\\n\", metrics_df, \"\\n\")\n",
    "save_output(metrics_df, \"test_metrics_with_without_grades.csv\")\n",
    "\n",
    "# -------------------- VISUALIZATION - RMSE & R² COMPARISON --------------------\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# RMSE barplot\n",
    "sns.barplot(\n",
    "    x=\"setting\",\n",
    "    y=\"rmse\",\n",
    "    data=metrics_df,\n",
    "    palette=\"Blues\",\n",
    "    ax=axes[0],\n",
    ")\n",
    "axes[0].set_title(\"Root Mean Squared Error (RMSE)\")\n",
    "axes[0].set_ylabel(\"RMSE\")\n",
    "axes[0].set_xlabel(\"Model Setting\")\n",
    "\n",
    "# R² barplot\n",
    "sns.barplot(\n",
    "    x=\"setting\",\n",
    "    y=\"r2\",\n",
    "    data=metrics_df,\n",
    "    palette=\"Greens\",\n",
    "    ax=axes[1],\n",
    ")\n",
    "axes[1].set_title(\"R² (Coefficient of Determination)\")\n",
    "axes[1].set_ylabel(\"R²\")\n",
    "axes[1].set_xlabel(\"Model Setting\")\n",
    "axes[1].set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_plot(\"rmse_r2_with_vs_without_grades.png\", width=14, height=6, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# -------------------- AT-RISK STUDENT ANALYSIS --------------------\n",
    "# Define at-risk: final grade < 10\n",
    "y_true_at_risk = (y_test < 10).astype(int)\n",
    "y_pred_at_risk = (y_pred_with < 10).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_true_at_risk, y_pred_at_risk)\n",
    "print(\"=== At-Risk Classification (Using Best SVR Regression) ===\")\n",
    "print(\"Confusion matrix (0 = not at risk, 1 = at risk):\\n\", cm, \"\\n\")\n",
    "\n",
    "print(\"Classification report:\\n\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_true_at_risk,\n",
    "        y_pred_at_risk,\n",
    "        target_names=[\"Not at risk\", \"At risk\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "# -------------------- SAVE BEST MODEL (WITH GRADES) --------------------\n",
    "model_path = models_dir / \"school_best_svm_with_grades.pkl\"\n",
    "joblib.dump(best_svm_with, model_path)\n",
    "print(f\"\\nSaved best model to: {model_path}\")\n",
    "\n",
    "# ---------- DEMO PREDICTIONS ----------\n",
    "demo_preds = best_svm_with.predict(X_test_transformed_with[:5])\n",
    "print(\"\\nDemo predictions (first 5 test rows):\")\n",
    "print(\"Predicted G3:\", np.round(demo_preds, 2))\n",
    "print(\"Actual   G3:\", y_test.iloc[:5].values)\n",
    "\n",
    "# -------------------- PIPELINE COMPLETE --------------------\n",
    "print(\"\\nPipeline complete:\")\n",
    "print(\"- Project setup (figures/, outputs/, models/ directories)\")\n",
    "print(\"- Data loading & validation (shape, dtypes, missingness)\")\n",
    "print(\"- EDA outputs saved (numeric/categorical/ordinal summaries)\")\n",
    "print(\"- Correlation analysis for numeric features + heatmap\")\n",
    "print(\"- ANOVA feature screening + significant boxplots\")\n",
    "print(\"- Stratified train/test split\")\n",
    "print(\"- Feature engineering: absences_sum and optional removal of G1/G2\")\n",
    "print(\"- Preprocessing pipelines: imputation + scaling + one-hot + ordinal encoding\")\n",
    "print(\"- Baseline model comparison (Linear, Lasso, SVR) using CV RMSE\")\n",
    "print(\"- Hyperparameter tuning: GridSearchCV for SVR (with vs without grades)\")\n",
    "print(\"- Final evaluation on held-out test set (RMSE, MAE, R²)\")\n",
    "print(\"- At-risk view derived from regression (G3 < 10) + confusion matrix/report\")\n",
    "print(\"- Artifacts saved to /figures, /outputs, and /models\")\n",
    "print(f\"- Best model saved as {model_path.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca505419-423d-428a-be4e-f79ee3e377b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
